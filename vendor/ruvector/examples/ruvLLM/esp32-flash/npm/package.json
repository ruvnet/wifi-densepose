{
  "name": "ruvllm-esp32",
  "version": "0.3.1",
  "description": "RuvLLM ESP32 - Tiny LLM inference for ESP32 microcontrollers with INT8 quantization, RAG, HNSW vector search, and multi-chip federation. Run AI on $4 hardware.",
  "keywords": [
    "esp32",
    "llm",
    "ai",
    "inference",
    "embedded",
    "microcontroller",
    "rag",
    "vector-search",
    "hnsw",
    "quantization",
    "edge-ai",
    "iot",
    "machine-learning",
    "neural-network",
    "esp32-s3",
    "xtensa",
    "riscv",
    "offline-ai",
    "tiny-ml",
    "semantic-memory"
  ],
  "author": "RuVector Team",
  "license": "MIT",
  "repository": {
    "type": "git",
    "url": "https://github.com/ruvnet/ruvector.git",
    "directory": "examples/ruvLLM/esp32-flash"
  },
  "homepage": "https://github.com/ruvnet/ruvector/tree/main/examples/ruvLLM/esp32-flash",
  "bugs": {
    "url": "https://github.com/ruvnet/ruvector/issues"
  },
  "bin": {
    "ruvllm-esp32": "./bin/cli.js"
  },
  "files": [
    "bin/",
    "binaries/",
    "scripts/",
    "templates/",
    "web-flasher/",
    "README.md"
  ],
  "scripts": {
    "postinstall": "node bin/postinstall.js"
  },
  "engines": {
    "node": ">=16.0.0"
  },
  "os": [
    "darwin",
    "linux",
    "win32"
  ],
  "cpu": [
    "x64",
    "arm64"
  ],
  "preferGlobal": true
}
