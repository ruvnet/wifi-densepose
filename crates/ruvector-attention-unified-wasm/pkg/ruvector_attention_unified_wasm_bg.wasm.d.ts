/* tslint:disable */
/* eslint-disable */
export const memory: WebAssembly.Memory;
export const __wbg_dagattentionfactory_free: (a: number, b: number) => void;
export const __wbg_get_mambaconfig_conv_kernel_size: (a: number) => number;
export const __wbg_get_mambaconfig_dim: (a: number) => number;
export const __wbg_get_mambaconfig_dt_max: (a: number) => number;
export const __wbg_get_mambaconfig_dt_min: (a: number) => number;
export const __wbg_get_mambaconfig_expand_factor: (a: number) => number;
export const __wbg_get_mambaconfig_state_dim: (a: number) => number;
export const __wbg_get_mambaconfig_use_d_skip: (a: number) => number;
export const __wbg_get_wasmsearchconfig_temperature: (a: number) => number;
export const __wbg_hybridmambaattention_free: (a: number, b: number) => void;
export const __wbg_mambaconfig_free: (a: number, b: number) => void;
export const __wbg_mambassmattention_free: (a: number, b: number) => void;
export const __wbg_set_mambaconfig_conv_kernel_size: (a: number, b: number) => void;
export const __wbg_set_mambaconfig_dim: (a: number, b: number) => void;
export const __wbg_set_mambaconfig_dt_max: (a: number, b: number) => void;
export const __wbg_set_mambaconfig_dt_min: (a: number, b: number) => void;
export const __wbg_set_mambaconfig_expand_factor: (a: number, b: number) => void;
export const __wbg_set_mambaconfig_state_dim: (a: number, b: number) => void;
export const __wbg_set_mambaconfig_use_d_skip: (a: number, b: number) => void;
export const __wbg_set_wasmsearchconfig_temperature: (a: number, b: number) => void;
export const __wbg_unifiedattention_free: (a: number, b: number) => void;
export const __wbg_wasmcausalconeattention_free: (a: number, b: number) => void;
export const __wbg_wasmflashattention_free: (a: number, b: number) => void;
export const __wbg_wasmgnnlayer_free: (a: number, b: number) => void;
export const __wbg_wasmhyperbolicattention_free: (a: number, b: number) => void;
export const __wbg_wasmlinearattention_free: (a: number, b: number) => void;
export const __wbg_wasmmincutgatedattention_free: (a: number, b: number) => void;
export const __wbg_wasmmoeattention_free: (a: number, b: number) => void;
export const __wbg_wasmmultiheadattention_free: (a: number, b: number) => void;
export const __wbg_wasmquerydag_free: (a: number, b: number) => void;
export const __wbg_wasmtensorcompress_free: (a: number, b: number) => void;
export const availableMechanisms: () => number;
export const cosineSimilarity: (a: number, b: number, c: number, d: number, e: number) => void;
export const dagattentionfactory_availableTypes: () => number;
export const dagattentionfactory_getDescription: (a: number, b: number, c: number) => void;
export const getStats: () => number;
export const graphDifferentiableSearch: (a: number, b: number, c: number, d: number, e: number) => void;
export const graphHierarchicalForward: (a: number, b: number, c: number, d: number, e: number, f: number) => void;
export const graphattentionfactory_availableTypes: () => number;
export const graphattentionfactory_getDescription: (a: number, b: number, c: number) => void;
export const graphattentionfactory_getUseCases: (a: number, b: number) => number;
export const hybridmambaattention_forward: (a: number, b: number, c: number, d: number, e: number) => void;
export const hybridmambaattention_localWindow: (a: number) => number;
export const hybridmambaattention_new: (a: number, b: number) => number;
export const mambaconfig_new: (a: number) => number;
export const mambaconfig_withConvKernelSize: (a: number, b: number) => number;
export const mambaconfig_withExpandFactor: (a: number, b: number) => number;
export const mambaconfig_withStateDim: (a: number, b: number) => number;
export const mambassmattention_config: (a: number) => number;
export const mambassmattention_forward: (a: number, b: number, c: number, d: number, e: number) => void;
export const mambassmattention_getAttentionScores: (a: number, b: number, c: number, d: number, e: number) => void;
export const mambassmattention_innerDim: (a: number) => number;
export const mambassmattention_new: (a: number) => number;
export const mambassmattention_withDefaults: (a: number) => number;
export const scaledDotAttention: (a: number, b: number, c: number, d: number, e: number, f: number) => void;
export const softmax: (a: number, b: number, c: number) => void;
export const temperatureSoftmax: (a: number, b: number, c: number, d: number) => void;
export const unifiedattention_category: (a: number, b: number) => void;
export const unifiedattention_mechanism: (a: number, b: number) => void;
export const unifiedattention_new: (a: number, b: number, c: number) => void;
export const unifiedattention_supportsGraphs: (a: number) => number;
export const unifiedattention_supportsHyperbolic: (a: number) => number;
export const unifiedattention_supportsSequences: (a: number) => number;
export const version: (a: number) => void;
export const wasmcausalconeattention_forward: (a: number, b: number, c: number) => void;
export const wasmcriticalpathattention_forward: (a: number, b: number, c: number) => void;
export const wasmflashattention_compute: (a: number, b: number, c: number, d: number, e: number, f: number) => void;
export const wasmflashattention_new: (a: number, b: number) => number;
export const wasmgnnlayer_forward: (a: number, b: number, c: number, d: number, e: number, f: number, g: number) => void;
export const wasmgnnlayer_new: (a: number, b: number, c: number, d: number, e: number) => void;
export const wasmgnnlayer_outputDim: (a: number) => number;
export const wasmhierarchicallorentzattention_forward: (a: number, b: number, c: number) => void;
export const wasmhyperbolicattention_compute: (a: number, b: number, c: number, d: number, e: number, f: number) => void;
export const wasmhyperbolicattention_curvature: (a: number) => number;
export const wasmhyperbolicattention_new: (a: number, b: number) => number;
export const wasmlinearattention_compute: (a: number, b: number, c: number, d: number, e: number, f: number) => void;
export const wasmlinearattention_new: (a: number, b: number) => number;
export const wasmlocalglobalattention_compute: (a: number, b: number, c: number, d: number, e: number, f: number) => void;
export const wasmlocalglobalattention_new: (a: number, b: number, c: number) => number;
export const wasmmincutgatedattention_forward: (a: number, b: number, c: number) => void;
export const wasmmoeattention_compute: (a: number, b: number, c: number, d: number, e: number, f: number) => void;
export const wasmmoeattention_new: (a: number, b: number, c: number) => number;
export const wasmmultiheadattention_compute: (a: number, b: number, c: number, d: number, e: number, f: number) => void;
export const wasmmultiheadattention_dim: (a: number) => number;
export const wasmmultiheadattention_headDim: (a: number) => number;
export const wasmmultiheadattention_new: (a: number, b: number, c: number) => void;
export const wasmmultiheadattention_numHeads: (a: number) => number;
export const wasmparallelbranchattention_forward: (a: number, b: number, c: number) => void;
export const wasmquerydag_addEdge: (a: number, b: number, c: number) => number;
export const wasmquerydag_addNode: (a: number, b: number, c: number, d: number) => number;
export const wasmquerydag_edgeCount: (a: number) => number;
export const wasmquerydag_new: () => number;
export const wasmquerydag_nodeCount: (a: number) => number;
export const wasmquerydag_toJson: (a: number, b: number) => void;
export const wasmtemporalbtspattention_forward: (a: number, b: number, c: number) => void;
export const wasmtensorcompress_compress: (a: number, b: number, c: number, d: number, e: number) => void;
export const wasmtensorcompress_compressWithLevel: (a: number, b: number, c: number, d: number, e: number, f: number) => void;
export const wasmtensorcompress_decompress: (a: number, b: number, c: number) => void;
export const wasmtensorcompress_getCompressionRatio: (a: number, b: number) => number;
export const wasmtensorcompress_new: () => number;
export const wasmtopologicalattention_forward: (a: number, b: number, c: number) => void;
export const init: () => void;
export const wasmmincutgatedattention_new: (a: number) => number;
export const wasmtopologicalattention_new: (a: number) => number;
export const __wbg_set_wasmsearchconfig_k: (a: number, b: number) => void;
export const wasmcausalconeattention_new: (a: number, b: number) => number;
export const wasmcriticalpathattention_new: (a: number, b: number) => number;
export const wasmhierarchicallorentzattention_new: (a: number, b: number) => number;
export const wasmparallelbranchattention_new: (a: number, b: number) => number;
export const wasmsearchconfig_new: (a: number, b: number) => number;
export const wasmtemporalbtspattention_new: (a: number, b: number) => number;
export const __wbg_get_wasmsearchconfig_k: (a: number) => number;
export const __wbg_graphattentionfactory_free: (a: number, b: number) => void;
export const __wbg_wasmcriticalpathattention_free: (a: number, b: number) => void;
export const __wbg_wasmhierarchicallorentzattention_free: (a: number, b: number) => void;
export const __wbg_wasmlocalglobalattention_free: (a: number, b: number) => void;
export const __wbg_wasmparallelbranchattention_free: (a: number, b: number) => void;
export const __wbg_wasmsearchconfig_free: (a: number, b: number) => void;
export const __wbg_wasmtemporalbtspattention_free: (a: number, b: number) => void;
export const __wbg_wasmtopologicalattention_free: (a: number, b: number) => void;
export const __wbindgen_export: (a: number, b: number) => number;
export const __wbindgen_export2: (a: number, b: number, c: number, d: number) => number;
export const __wbindgen_export3: (a: number) => void;
export const __wbindgen_export4: (a: number, b: number, c: number) => void;
export const __wbindgen_add_to_stack_pointer: (a: number) => number;
export const __wbindgen_start: () => void;
